{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ew7HTbPpCJH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zXXx5Oc3pOmN"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"tensorflow\") \\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://127.0.0.1/hotel.clean\") \\\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb://127.0.0.1/hotel.tensorflow\") \\\n",
    "    .config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.11:2.4.1') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zXXx5Oc3pOmN",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' The room was really completely sound proof We appreciated the bathroom with both tube and big shower cabin together with the super cozy bath ropes And if you like to listen to music properly don t forget to bring a little audio cable jack to jack The superior rooms are equipped with a Bose sound system but it doesn t have a bluethooth connection and you will need this cable ',\n",
       "       ' Excellent location good standard of hotel Professional service',\n",
       "       ' Location was reason for booking and was spot on Staff were all very pleasant Time was spent out and about as we were visiting friends and family so didn t use facilities or eat breakfast Room was clean and tidy with great black out curtains Check out swift and easy ',\n",
       "       ..., ' Area around hotel was a little too quiet',\n",
       "       ' It was horrible',\n",
       "       ' Pool was small and not heated rooms are quite small '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get reviews dataframe\n",
    "reviews = spark.read.format(\"mongo\").load()\n",
    "df = reviews.toPandas()\n",
    "df.review.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas dataframe to tf dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((df[\"review\"].values, df[\"sentiment\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "DATASET_SIZE = len(df)\n",
    "\n",
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "test_size = int(0.3 * DATASET_SIZE)\n",
    "\n",
    "shuffled_dataset = dataset.shuffle(DATASET_SIZE)\n",
    "train_data = dataset.take(train_size)\n",
    "test_dataset = dataset.skip(train_size)\n",
    "test_data = test_dataset.take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_NUbzVeYkgcO"
   },
   "outputs": [],
   "source": [
    "# use transfer learning\n",
    "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xpKOoWgu-llD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 20)                400020    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 400,373\n",
      "Trainable params: 400,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# setup neural network\n",
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mr0GP-cQ-llN"
   },
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tXSGrjWZ-llW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.7156 - accuracy: 0.3673 - val_loss: 0.8350 - val_accuracy: 0.7379\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.5060 - accuracy: 0.6817 - val_loss: 0.7131 - val_accuracy: 0.7893\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.4090 - accuracy: 0.8078 - val_loss: 0.6302 - val_accuracy: 0.8069\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.3429 - accuracy: 0.8529 - val_loss: 0.5847 - val_accuracy: 0.8129\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.2977 - accuracy: 0.8777 - val_loss: 0.5406 - val_accuracy: 0.8247\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.2672 - accuracy: 0.8928 - val_loss: 0.5115 - val_accuracy: 0.8340\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.2440 - accuracy: 0.9023 - val_loss: 0.4786 - val_accuracy: 0.8409\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.2279 - accuracy: 0.9111 - val_loss: 0.4569 - val_accuracy: 0.8518\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.2142 - accuracy: 0.9164 - val_loss: 0.4399 - val_accuracy: 0.8578\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.2033 - accuracy: 0.9218 - val_loss: 0.4210 - val_accuracy: 0.8661\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.1940 - accuracy: 0.9253 - val_loss: 0.4111 - val_accuracy: 0.8695\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.1854 - accuracy: 0.9291 - val_loss: 0.3964 - val_accuracy: 0.8744\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.1788 - accuracy: 0.9320 - val_loss: 0.3862 - val_accuracy: 0.8788\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.1719 - accuracy: 0.9343 - val_loss: 0.3819 - val_accuracy: 0.8796\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1678 - accuracy: 0.9372 - val_loss: 0.3661 - val_accuracy: 0.8861\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.1627 - accuracy: 0.9389 - val_loss: 0.3666 - val_accuracy: 0.8858\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1579 - accuracy: 0.9403 - val_loss: 0.3584 - val_accuracy: 0.8891\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.1541 - accuracy: 0.9415 - val_loss: 0.3547 - val_accuracy: 0.8897\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.1503 - accuracy: 0.9431 - val_loss: 0.3475 - val_accuracy: 0.8918\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.1475 - accuracy: 0.9445 - val_loss: 0.3441 - val_accuracy: 0.8938\n",
      "It took 14.295791864395142 seconds to train.\n"
     ]
    }
   ],
   "source": [
    "# record training time\n",
    "t0 = time()\n",
    "\n",
    "# train model using 20 epochs in mini-batches of 512 samples\n",
    "history = model.fit(train_data.shuffle(10000).batch(512),\n",
    "                    epochs=20,\n",
    "                    validation_data=test_data.batch(512),\n",
    "                    verbose=1)\n",
    "\n",
    "tt = time() - t0\n",
    "print(\"It took {} seconds to train.\".format(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOMKywn4zReN",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 - 0s - loss: 0.3441 - accuracy: 0.8938\n",
      "loss: 0.344\n",
      "accuracy: 0.894\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "results = model.evaluate(test_data.batch(512), verbose=2)\n",
    "\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "  print(\"%s: %.3f\" % (name, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-902417979b4a>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-902417979b4a>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "# predict test set\n",
    "prediction = model.predict_classes(test_data.batch(512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numpy array of reviews of test_data\n",
    "test_data_values, test_data_labels = next(iter(test_data.batch(test_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating our model along more metrics\n",
    "predicted = prediction.flatten()\n",
    "actual = test_data_labels\n",
    "TP = tf.math.count_nonzero(predicted * actual).numpy()\n",
    "TN = tf.math.count_nonzero((predicted - 1) * (actual - 1)).numpy()\n",
    "FP = tf.math.count_nonzero(predicted * (actual - 1)).numpy()\n",
    "FN = tf.math.count_nonzero((predicted - 1) * actual).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 9.699320106758477e-08 \n",
      "Recall: 1.0 \n",
      " F1: 1.9398638331980927e-07\n"
     ]
    }
   ],
   "source": [
    "# check to avoid divide-by-zero\n",
    "if TP == 0:\n",
    "    TP = 0.0001\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "print(\"Precision: {} \\nRecall: {} \\n F1: {}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# removes 'b' char in front of every review\n",
    "test_data_values = np.array([x.decode() for x in test_data_values.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe of reviews and sentiment to write to mongo\n",
    "final_df = pd.DataFrame({\"review\": test_data_values, \"sentiment\": prediction[:, 0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write predicted reviews to mongo\n",
    "spark \\\n",
    "    .createDataFrame(final_df) \\\n",
    "    .write.format(\"mongo\").mode(\"append\").save()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "text_classification_with_hub.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
